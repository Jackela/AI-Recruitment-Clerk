/**
 * æ€§èƒ½ç›‘æ§æ‹¦æˆªå™¨
 * AI Recruitment Clerk - å®æ—¶æ€§èƒ½è¿½è¸ªä¸ä¼˜åŒ–
 */

import type {
  NestInterceptor,
  ExecutionContext,
  CallHandler} from '@nestjs/common';
import {
  Injectable,
  Logger,
} from '@nestjs/common';
import type { Observable } from 'rxjs';
import { tap } from 'rxjs/operators';
import type { CacheService } from '../../cache/cache.service';

/**
 * Defines the shape of the performance metrics.
 */
export interface PerformanceMetrics {
  endpoint: string;
  method: string;
  responseTime: number;
  statusCode: number;
  timestamp: number;
  userId?: string;
  cacheHit?: boolean;
  dbQueryTime?: number;
  redisQueryTime?: number;
}

/**
 * Represents the performance monitoring interceptor.
 */
@Injectable()
export class PerformanceMonitoringInterceptor implements NestInterceptor {
  private readonly logger: Logger = new Logger(PerformanceMonitoringInterceptor.name);
  private readonly performanceThresholds: { warning: number; critical: number } = {
    warning: 200, // 200ms
    critical: 500, // 500ms
  };

  /**
   * Initializes a new instance of the Performance Monitoring Interceptor.
   * @param cacheService - The cache service.
   */
  constructor(private readonly cacheService: CacheService) {}

  /**
   * Performs the intercept operation.
   * @param context - The context.
   * @param next - The next.
   * @returns The Observable<unknown>.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  public intercept(context: ExecutionContext, next: CallHandler): Observable<any> {
    const startTime = Date.now();
    const request = context.switchToHttp().getRequest();
    const response = context.switchToHttp().getResponse();

    const endpoint = `${request.method} ${request.route?.path || request.url}`;
    const method = request.method;
    const userId = request.user?.id;

    return next.handle().pipe(
      tap({
        next: (data) => {
          this.recordPerformanceMetric(
            startTime,
            endpoint,
            method,
            response.statusCode,
            userId,
            request,
            data,
          );
        },
        error: (error) => {
          this.recordPerformanceMetric(
            startTime,
            endpoint,
            method,
            error.status || 500,
            userId,
            request,
            null,
            error,
          );
        },
      }),
    );
  }

  private async recordPerformanceMetric(
    startTime: number,
    endpoint: string,
    method: string,
    statusCode: number,
    userId?: string,
    request?: Record<string, unknown>,
    _data?: unknown,
    error?: { status?: number; message?: string },
  ): Promise<void> {
    const responseTime = Date.now() - startTime;
    const timestamp = Date.now();

    // æå–ç¼“å­˜å‘½ä¸­ä¿¡æ¯
    const cacheHit = typeof request?.cacheHit === 'boolean' ? request.cacheHit : false;
    const dbQueryTime = typeof request?.dbQueryTime === 'number' ? request.dbQueryTime : 0;
    const redisQueryTime = typeof request?.redisQueryTime === 'number' ? request.redisQueryTime : 0;

    const metrics: PerformanceMetrics = {
      endpoint,
      method,
      responseTime,
      statusCode,
      timestamp,
      userId,
      cacheHit,
      dbQueryTime,
      redisQueryTime,
    };

    // è®°å½•æ€§èƒ½æŒ‡æ ‡
    await this.storeMetrics(metrics);

    // æ€§èƒ½è­¦å‘Šæ£€æŸ¥
    this.checkPerformanceThresholds(metrics, error);

    // å®æ—¶æ€§èƒ½æ—¥å¿—
    this.logPerformance(metrics, error);
  }

  private async storeMetrics(metrics: PerformanceMetrics): Promise<void> {
    try {
      // å­˜å‚¨åˆ°Redisè¿›è¡Œå®æ—¶ç›‘æ§
      const metricsKey = this.cacheService.generateKey(
        'performance',
        'metrics',
        new Date().toISOString().split('T')[0], // æŒ‰æ—¥æœŸåˆ†ç»„
        Math.floor(Date.now() / 300000).toString(), // 5åˆ†é’Ÿçª—å£
      );

      // è·å–ç°æœ‰æŒ‡æ ‡
      const existingMetrics =
        (await this.cacheService.get<PerformanceMetrics[]>(metricsKey)) || [];
      existingMetrics.push(metrics);

      // ä¿ç•™æœ€è¿‘100æ¡è®°å½•
      if (existingMetrics.length > 100) {
        existingMetrics.splice(0, existingMetrics.length - 100);
      }

      // å­˜å‚¨æ›´æ–°çš„æŒ‡æ ‡ï¼ˆ1å°æ—¶TTLï¼‰
      await this.cacheService.set(metricsKey, existingMetrics, {
        ttl: 3600000,
      });

      // æ›´æ–°å®æ—¶ç»Ÿè®¡
      await this.updateRealtimeStats(metrics);
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      this.logger.warn('Failed to store performance metrics:', errorMessage);
    }
  }

  private async updateRealtimeStats(metrics: PerformanceMetrics): Promise<void> {
    try {
      const statsKey = this.cacheService.generateKey(
        'performance',
        'stats',
        'realtime',
      );
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const stats: any = (await this.cacheService.get(statsKey)) ?? {
        totalRequests: 0,
        averageResponseTime: 0,
        slowRequests: 0,
        cacheHitRate: 0,
        errorRate: 0,
        lastUpdated: Date.now(),
        endpointStats: {},
      };

      // æ›´æ–°æ€»ä½“ç»Ÿè®¡
      stats.totalRequests += 1;
      stats.averageResponseTime =
        (stats.averageResponseTime * (stats.totalRequests - 1) +
          metrics.responseTime) /
        stats.totalRequests;

      if (metrics.responseTime > this.performanceThresholds.warning) {
        stats.slowRequests += 1;
      }

      if (metrics.statusCode >= 400) {
        stats.errorRate =
          (stats.errorRate * (stats.totalRequests - 1) + 1) /
          stats.totalRequests;
      } else {
        stats.errorRate =
          (stats.errorRate * (stats.totalRequests - 1)) / stats.totalRequests;
      }

      if (metrics.cacheHit !== undefined) {
        const currentHits = stats.cacheHitRate * (stats.totalRequests - 1);
        stats.cacheHitRate =
          (currentHits + (metrics.cacheHit ? 1 : 0)) / stats.totalRequests;
      }

      // æ›´æ–°ç«¯ç‚¹ç‰¹å®šç»Ÿè®¡
      if (!stats.endpointStats[metrics.endpoint]) {
        stats.endpointStats[metrics.endpoint] = {
          count: 0,
          averageTime: 0,
          minTime: metrics.responseTime,
          maxTime: metrics.responseTime,
          errors: 0,
        };
      }

      const endpointStat = stats.endpointStats[metrics.endpoint];
      endpointStat.count += 1;
      endpointStat.averageTime =
        (endpointStat.averageTime * (endpointStat.count - 1) +
          metrics.responseTime) /
        endpointStat.count;
      endpointStat.minTime = Math.min(
        endpointStat.minTime,
        metrics.responseTime,
      );
      endpointStat.maxTime = Math.max(
        endpointStat.maxTime,
        metrics.responseTime,
      );

      if (metrics.statusCode >= 400) {
        endpointStat.errors += 1;
      }

      stats.lastUpdated = Date.now();

      // å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆ10åˆ†é’ŸTTLï¼‰
      await this.cacheService.set(statsKey, stats, { ttl: 600000 });
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      this.logger.warn('Failed to update realtime stats:', errorMessage);
    }
  }

  private checkPerformanceThresholds(metrics: PerformanceMetrics, error?: { message?: string }): void {
    const { responseTime, endpoint } = metrics;

    if (responseTime > this.performanceThresholds.critical) {
      this.logger.error(
        `ğŸš¨ CRITICAL: Slow response detected - ${endpoint} took ${responseTime}ms`,
        { metrics, error: error?.message },
      );
    } else if (responseTime > this.performanceThresholds.warning) {
      this.logger.warn(
        `âš ï¸ WARNING: Slow response detected - ${endpoint} took ${responseTime}ms`,
        { metrics },
      );
    }
  }

  private logPerformance(metrics: PerformanceMetrics, error?: { message?: string }): void {
    const {
      endpoint,
      responseTime,
      statusCode,
      cacheHit,
      dbQueryTime,
      redisQueryTime,
    } = metrics;

    const performanceInfo = [
      `${responseTime}ms`,
      cacheHit ? 'ğŸ“Š CACHE' : 'ğŸ” DB',
      (dbQueryTime ?? 0) > 0 ? `DB:${dbQueryTime}ms` : '',
      (redisQueryTime ?? 0) > 0 ? `Redis:${redisQueryTime}ms` : '',
    ]
      .filter(Boolean)
      .join(' ');

    if (error) {
      this.logger.error(
        `âŒ ${endpoint} | ${statusCode} | ${performanceInfo} | ERROR: ${error.message}`,
      );
    } else if (responseTime > this.performanceThresholds.warning) {
      this.logger.warn(
        `âš ï¸ ${endpoint} | ${statusCode} | ${performanceInfo} | SLOW`,
      );
    } else {
      this.logger.debug(`âœ… ${endpoint} | ${statusCode} | ${performanceInfo}`);
    }
  }

  // è·å–æ€§èƒ½ç»Ÿè®¡çš„å…¬å…±æ–¹æ³•
  /**
   * Retrieves performance stats.
   * @returns A promise that resolves to the performance stats.
   */
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  public async getPerformanceStats(): Promise<any> {
    try {
      const statsKey = this.cacheService.generateKey(
        'performance',
        'stats',
        'realtime',
      );
      return (
        (await this.cacheService.get(statsKey)) || {
          totalRequests: 0,
          averageResponseTime: 0,
          slowRequests: 0,
          cacheHitRate: 0,
          errorRate: 0,
          lastUpdated: Date.now(),
          endpointStats: {},
        }
      );
    } catch (error) {
      this.logger.error('Failed to get performance stats:', error);
      return null;
    }
  }

  // è·å–å†å²æŒ‡æ ‡
  /**
   * Retrieves historical metrics.
   * @param date - The date.
   * @param window - The window.
   * @returns A promise that resolves to an array of PerformanceMetrics.
   */
  public async getHistoricalMetrics(
    date?: string,
    window?: string,
  ): Promise<PerformanceMetrics[]> {
    try {
      const targetDate = date || new Date().toISOString().split('T')[0];
      const targetWindow = window || Math.floor(Date.now() / 300000).toString();

      const metricsKey = this.cacheService.generateKey(
        'performance',
        'metrics',
        targetDate,
        targetWindow,
      );

      return (
        (await this.cacheService.get<PerformanceMetrics[]>(metricsKey)) || []
      );
    } catch (error) {
      this.logger.error('Failed to get historical metrics:', error);
      return [];
    }
  }

  // æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
  /**
   * Generates performance report.
   * @returns The Promise with summary, slowestEndpoints, and recommendations.
   */
  public async generatePerformanceReport(): Promise<{
    summary: Record<string, unknown>;
    slowestEndpoints: Array<{ endpoint: string; averageTime: number; maxTime: number; count: number; errorRate: number }>;
    recommendations: string[];
  }> {
    try {
      const stats = await this.getPerformanceStats();

      if (!stats || stats.totalRequests === 0) {
        return {
          summary: { message: 'No performance data available' },
          slowestEndpoints: [],
          recommendations: [],
        };
      }

      // æ‰¾å‡ºæœ€æ…¢çš„ç«¯ç‚¹
      const slowestEndpoints = Object.entries(stats.endpointStats)
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        .map(([endpoint, stat]: [string, any]) => ({
          endpoint,
          averageTime: stat.averageTime,
          maxTime: stat.maxTime,
          count: stat.count,
          errorRate: stat.errors / stat.count,
        }))
        .sort((a, b) => b.averageTime - a.averageTime)
        .slice(0, 10);

      // ç”Ÿæˆæ€§èƒ½å»ºè®®
      const recommendations = this.generateRecommendations(
        stats,
        slowestEndpoints,
      );

      return {
        summary: {
          totalRequests: stats.totalRequests,
          averageResponseTime: Math.round(stats.averageResponseTime),
          slowRequestPercentage: Math.round(
            (stats.slowRequests / stats.totalRequests) * 100,
          ),
          cacheHitRate: Math.round(stats.cacheHitRate * 100),
          errorRate: Math.round(stats.errorRate * 100),
          lastUpdated: new Date(stats.lastUpdated).toISOString(),
        },
        slowestEndpoints,
        recommendations,
      };
    } catch (error) {
      this.logger.error('Failed to generate performance report:', error);
      throw error;
    }
  }

  private generateRecommendations(
    stats: Record<string, unknown> & { cacheHitRate: number; errorRate: number; averageResponseTime: number; slowRequests: number; totalRequests: number },
    slowestEndpoints: Array<{ endpoint: string; averageTime: number }>,
  ): string[] {
    const recommendations: string[] = [];

    if (stats.cacheHitRate < 0.5) {
      recommendations.push('ç¼“å­˜å‘½ä¸­ç‡ä½äº50%ï¼Œå»ºè®®å¢åŠ ç¼“å­˜ç­–ç•¥å’ŒTTLä¼˜åŒ–');
    }

    if (stats.errorRate > 0.05) {
      recommendations.push('é”™è¯¯ç‡è¶…è¿‡5%ï¼Œéœ€è¦æ£€æŸ¥é”™è¯¯å¤„ç†å’Œç³»ç»Ÿç¨³å®šæ€§');
    }

    if (stats.averageResponseTime > 150) {
      recommendations.push('å¹³å‡å“åº”æ—¶é—´è¶…è¿‡150msï¼Œå»ºè®®è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–');
    }

    if (slowestEndpoints.length > 0 && slowestEndpoints[0].averageTime > 300) {
      recommendations.push(
        `æœ€æ…¢ç«¯ç‚¹ ${slowestEndpoints[0].endpoint} å¹³å‡å“åº”æ—¶é—´è¶…è¿‡300msï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–`,
      );
    }

    const slowRequestPercentage =
      (stats.slowRequests / stats.totalRequests) * 100;
    if (slowRequestPercentage > 10) {
      recommendations.push('è¶…è¿‡10%çš„è¯·æ±‚å“åº”ç¼“æ…¢ï¼Œå»ºè®®è¿›è¡Œç³»ç»Ÿæ€§èƒ½è°ƒä¼˜');
    }

    if (recommendations.length === 0) {
      recommendations.push('ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰ä¼˜åŒ–ç­–ç•¥');
    }

    return recommendations;
  }
}
